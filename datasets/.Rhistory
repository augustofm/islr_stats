train <- dt[1:1000,]
test <- setdiff(dt, train)
test
nrow(dt)
test <- dt[1001:nrow(dt),]
gbm(Purchase ~ ., train,
n.trees = 1000,
shrinkage = 0.01)
gbm(Purchase ~ ., data = train,
n.trees = 1000,
shrinkage = 0.01)
boost.model <- gbm(Purchase ~ ., data = train,
n.trees = 1000,
shrinkage = 0.01)
boost.model <- gbm(Purchase ~ ., data = train,
distribution = "gaussian",
n.trees = 1000,
shrinkage = 0.01)
boost.model <- gbm(Purchase ~ ., data = train,
distribution = "gaussian",
n.trees = 1000,
shrinkage = 0.01,
verbose = F)
train
boost.sum <- summary(boost.model)
boost.sum <- data.table(boost.sum)
setorder(boost.sum, -rel.inf)
head(boost.sum)
boost.sum
# (c)
predict(boost.model, test)
# (c)
predict(boost.model, test, n.trees = 1000)
summary(train$Purchase)
dt[, Purchase := ifelse (Purchase == "Yes", 1, 0)]
train <- dt[1:1000,]
test <- dt[1001:nrow(dt),]
boost.model <- gbm(Purchase ~ ., data = train,
distribution = "gaussian",
n.trees = 1000,
shrinkage = 0.01,
verbose = F)
boost.sum <- summary(boost.model)
boost.sum <- data.table(boost.sum)
setorder(boost.sum, -rel.inf)
# Most important variables
head(boost.sum)
# (c)
predict(boost.model, test, n.trees = 1000)
summary(train$Purchase)
# (c)
predict(boost.model, test, n.trees = 1000, type = "prob")
# (c)
summary(predict(boost.model, test, n.trees = 1000))
dt <- data.table(Caravan)
nrow(dt)
#dt[, Purchase := ifelse (Purchase == "Yes", 1, 0)]
train <- dt[1:1000,]
test <- dt[1001:nrow(dt),]
boost.model <- gbm(Purchase ~ ., data = train,
distribution = "gaussian",
n.trees = 1000,
shrinkage = 0.01,
verbose = F)
?gbm
boost.model <- gbm(Purchase ~ ., data = train,
distribution = "bernoulli",
n.trees = 1000,
shrinkage = 0.01,
verbose = F)
boost.sum <- summary(boost.model)
boost.sum <- data.table(boost.sum)
setorder(boost.sum, -rel.inf)
# Most important variables
head(boost.sum)
# (c)
summary(predict(boost.model, test, n.trees = 1000))
# (c)
predict(boost.model, test, n.trees = 1000)
?gbm
# (c)
predict(boost.model, test, n.trees = 1000, type = "prob")
# (c)
predict(boost.model, test, n.trees = 1000, type = "response")
# (c)
predict(boost.model, newdata = test, n.trees = 1000, type = "response")
# (c)
predict(boost.model, test, n.trees = 1000, type = "prob")
# (c)
predict(boost.model, newdata = test, n.trees = 1000)
# (c)
pred.odds <- predict(boost.model, newdata = test, n.trees = 1000)
data.table(Purchase = test$Purchase,
pred.odds = pred.odds)
test.results <- data.table(Purchase = test$Purchase,
pred.odds = pred.odds)
test.results[, pred := pred.oods/(1+pred.odds)]
test.results[, pred := pred.odds/(1+pred.odds)]
test.results
test.results[, pred.label := ifelse(pred>=0.2, "Yes", "No")]
test.results
summary(test.results$pred.label)
summary(test.results$pred)
# (c)
pred.odds <- predict(boost.model, newdata = test, n.trees = 1000,
type = "response")
test.results <- data.table(Purchase = test$Purchase,
pred.odds = pred.odds)
test.results[, prob := pred.odds/(1+pred.odds)]
test.results[, pred := ifelse(prob>=0.2, "Yes", "No")]
summary(test.results$prob)
boost.model <- gbm(Purchase ~ ., data = train,
distribution = "bernoulli",
n.trees = 1000,
shrinkage = 0.01,
verbose = F)
# (c)
pred.odds <- predict(boost.model, newdata = test, n.trees = 1000)
test.results <- data.table(Purchase = test$Purchase,
pred.odds = pred.odds)
test.results[, prob := pred.odds/(1+pred.odds)]
test.results[, pred := ifelse(prob>=0.2, "Yes", "No")]
summary(test.results$prob)
test.results[, prob := plogis(pred.odds)]
test.results[, pred := ifelse(prob>=0.2, "Yes", "No")]
summary(test.results$prob)
#dt[, Purchase := ifelse (Purchase == "Yes", 1, 0)]
train <- dt[1:1000,]
test <- dt[1001:nrow(dt),]
# (c)
pred.odds <- predict(boost.model, newdata = test, n.trees = 1000)
test.results <- data.table(Purchase = test$Purchase,
pred.odds = pred.odds)
test.results[, prob := plogis(pred.odds)]
summary(test.results$prob)
# (c)
pred.odds <- predict.gbm(boost.model, newdata = test, n.trees = 1000)
test.results <- data.table(Purchase = test$Purchase,
pred.odds = pred.odds)
test.results[, prob := plogis(pred.odds)]
summary(test.results$prob)
# (c)
pred.odds <- predict.gbm(boost.model, newdata = test, n.trees = 1000,
type = response)
# (c)
pred.odds <- predict.gbm(boost.model, newdata = test, n.trees = 1000,
type = "response")
test.results <- data.table(Purchase = test$Purchase,
pred.odds = pred.odds)
test.results[, prob := plogis(pred.odds)]
summary(test.results$prob)
plot(test.results)
plot(test.results$pred.odds)
train
boost.model <- gbm(Purchase ~ ., data = train,
distribution = "bernoulli",
n.trees = 1000,
shrinkage = 0.01,
verbose = F)
dt[, Purchase := ifelse (Purchase == "Yes", 1, 0)]
train <- dt[1:1000,]
test <- dt[1001:nrow(dt),]
dt <- data.table(Caravan)
nrow(dt)
dt[, Purchase := ifelse (Purchase == "Yes", 1, 0)]
train <- dt[1:1000,]
test <- dt[1001:nrow(dt),]
boost.model <- gbm(Purchase ~ ., data = train,
distribution = "bernoulli",
n.trees = 1000,
shrinkage = 0.01,
verbose = F)
boost.sum <- data.table(boost.sum)
setorder(boost.sum, -rel.inf)
# Most important variables
head(boost.sum)
# (c)
pred.odds <- predict.gbm(boost.model,
newdata = test,
n.trees = 1000,
type = "response")
test.results <- data.table(Purchase = test$Purchase,
pred.odds = pred.odds)
test.results[, prob := plogis(pred.odds)]
plot(test.results$pred.odds)
summary(test.results$prob)
# (c)
pred.odds <- predict.gbm(boost.model,
newdata = test,
n.trees = 1000)
test.results <- data.table(Purchase = test$Purchase,
pred.odds = pred.odds)
test.results[, prob := plogis(pred.odds)]
summary(test.results$prob)
test.results[, pred := ifelse(prob>=0.2, "Yes", "No")]
dt <- data.table(Caravan)
nrow(dt)
dt.bk <- copy(dt)
dt[, Purchase := ifelse (Purchase == "Yes", 1, 0)]
dt.bk[1001:nrow(dt.bk),]$Purchase
table(test.results$pred, dt.bk[1001:nrow(dt.bk),]$Purchase)
# The fraction of the people predicted
# to make a purchase who do in fact make one is:
34/nrow(test)
# The fraction of the people predicted
# to make a purchase who do in fact make one is:
100*34/nrow(test)
# The fraction of the people predicted
# to make a purchase who do in fact make one is:
100*34/(34+121)
?knn
require(knn)
require(class)
?knn
knn(dt[1:1000], dt[1001:nrow(dt)], factor(dt$Purchase), k = 3, prob = TRUE)
knn(dt[1:1000], dt[1001:nrow(dt)], unique(factor(dt$Purchase)), k = 3, prob = TRUE)
knn(dt[1:1000], dt[1001:nrow(dt)], factor(train$Purchase), k = 3, prob = TRUE)
pred.knn <- knn(dt[1:1000], dt[1001:nrow(dt)], factor(train$Purchase), k = 3, prob = TRUE)
plot(pred.knn)
pred.knn <- knn(dt[1:1000], dt[1001:nrow(dt)], factor(train$Purchase), k = 3, prob = TRUE)
pred.knn
summary(pred.knn)
pred.knn <- knn(dt[1:1000], dt[1001:nrow(dt)], factor(train$Purchase),
k = 5,
prob = TRUE)
pred.knn <- knn(dt[1:1000], dt[1001:nrow(dt)], factor(dt[1:1000,]$Purchase),
k = 5,
prob = TRUE)
table(pred.knn, dt.bk[1001:nrow(dt.bk),]$Purchase)
pred.knn
pred.knn <- knn(dt[1:1000], dt[1001:nrow(dt)], factor(dt.bl[1:1000,]$Purchase),
k = 5,
prob = TRUE)
pred.knn <- knn(dt[1:1000], dt[1001:nrow(dt)], factor(dt.bk[1:1000,]$Purchase),
k = 5,
prob = TRUE)
table(pred.knn, dt.bk[1001:nrow(dt.bk),]$Purchase)
100*4/(29+4)
pred.knn <- knn(dt[1:1000], dt[1001:nrow(dt)], factor(dt.bk[1:1000,]$Purchase),
k = 3,
prob = TRUE)
table(pred.knn, dt.bk[1001:nrow(dt.bk),]$Purchase)
10/70
?knn
pred.knn <- knn(dt[1:1000], dt[1001:nrow(dt)], factor(dt.bk[1:1000,]$Purchase),
k = 3,
prob = FALSE)
pred.knn
pred.knn <- knn(dt[1:1000], dt[1001:nrow(dt)], factor(dt.bk[1:1000,]$Purchase),
k = 3,
prob = FALSE)
table(pred.knn, dt.bk[1001:nrow(dt.bk),]$Purchase)
pred.knn <- knn(dt[1:1000], dt[1001:nrow(dt)], factor(dt.bk[1:1000,]$Purchase),
k = 3)
table(pred.knn, dt.bk[1001:nrow(dt.bk),]$Purchase)
100*10/(62+10)
glm.fit <- glm(Purchase ~ .,
data = train,
family = binomial)
glm.prob <- predict(glm.fit, newdata = test,
type = "response")
glm.prob
glm.pred = rep("No", 1000)
glm.pred[glm.prob > 0.2] <- "Yes"
table(glm.pred, test$Purchase)
table(glm.pred, dt.bk[1001:nrow(dt.bk)$Purchase)
table(glm.pred, dt.bk[1001:nrow(dt.bk)]$Purchase)
100*58/(58+408)
require(readxl)
require(xlsx)
install.packages("xlsx")
require(readxl)
setwd("~/Documents/repository/islr_stats/datasets")
file.list()[1]
list.files()[1]
read_xlsx(list.files()[1])
read_xls(list.files()[1])
dt <- data.table(read_xls(list.files()[1]))
dt
str(dt)
summary(dt)
dt <- data.table(cars)
dt
summary(dt)
?MASS
dt <- data.table(iris)
summary(dt)
train <- sample(1:nrow(dt), 100)
# Boosting
gbm(Species ~ .,
data = dt[train],
distribution = "multinomial",
n.trees = 1000,
shrinkage = 0.002)
# Boosting
gbm(Species ~ .,
data = dt[train],
distribution = "multinomial",
n.trees = 1000,
shrinkage = 0.002,
verbose = F)
# Boosting
gbm.fit <- gbm(Species ~ .,
data = dt[train],
distribution = "multinomial",
n.trees = 1000,
shrinkage = 0.002,
verbose = F)
predict(gbm.fit, dt[-train], n.trees = 1000)
predict(gbm.fit, dt[-train], n.trees = 1000,
type = "rensponse")
predict(gbm.fit, dt[-train], n.trees = 1000,
type = "response")
0.006570404+0.02184695+0.971582645
predict(gbm.fit, dt[-train], n.trees = 1000,
type = "link")
predict(gbm.fit, dt[-train], n.trees = 1000,
type = "response")
prob <- predict(gbm.fit, dt[-train], n.trees = 1000,
type = "response")
names(prob)
head(prob)
prob
data.table(prob)
data.table(unlist(prob))
summary(dt)
setosa.prob <- prob[1,]
setosa.prob <- prob[1]
prob[1]
prob[,1]
prob[[1]]
prob <- predict(gbm.fit, dt[-train], n.trees = 1000)
prob
class(prob)
prob <- predict(gbm.fit, dt[-train], n.trees = 1000)
as.matrix(prob)
prob
logis(prob)
plogis(prob)
prob
plogis(prob)
prob <- predict(gbm.fit, dt[-train], n.trees = 1000,
type = "response")
prob
prob <- predict(gbm.fit, dt[-train], n.trees = 1000)
plogis(prob)
prob <- predict(gbm.fit,
dt[-train],
n.trees = 1000,
type = "response")
prob
as.data.frame(prob)
data.frame(prob)
results <- data.frame(prob)
names(results)
results <- data.table(data.frame(prob))
results
results[, pred := which.max(setosa.1000, versicolor.1000, virginica.1000)]
results[, pred := which(max(setosa.1000, versicolor.1000, virginica.1000))]
which(results == 0.9703)
which(results == 0.971482645)
results[, max := colnames(.SD)[max.col(.SD, ties.method="first")]]
reuslts
results
names(results) <- c("setosa", "versicolor", "virginica")
results <- data.table(data.frame(prob))
names(results) <- c("setosa", "versicolor", "virginica")
results[, max := colnames(.SD)[max.col(.SD, ties.method="first")]]
results
train <- sample(1:nrow(dt), 100)
train
# Boosting
gbm.fit <- gbm(Species ~ .,
data = dt[train],
distribution = "multinomial",
n.trees = 1000,
shrinkage = 0.002,
verbose = F)
prob <- predict(gbm.fit,
dt[-train],
n.trees = 1000,
type = "response")
results <- data.table(data.frame(prob))
names(results) <- c("setosa", "versicolor", "virginica")
results[, max := colnames(.SD)[max.col(.SD, ties.method="first")]]
results
results[, real := dt[-train]$Species]
results
table(results$max, results$real)
# randomForest
require(randomForest)
randomForest(Species ~ .,
data = dt[train],
ntree = 100)
rf <- randomForest(Species ~ .,
data = dt[train],
ntree = 100)
predict(rf, dt[-train, -c("Species")])
predict(rf, dt[-train])
pred <- predict(rf, dt[-train])
table(pred, dt[-train, Species])
names(ft)
names(dt)
rf <- randomForest(Species ~ .,
data = dt[train],
ntree = 100,
mtry = 4)
bag.rf <- randomForest(Species ~ .,
data = dt[train],
ntree = 100,
mtry = 4)
pred <- predict(bag.rf, dt[-train])
table(pred, dt[-train, Species])
# randomForest
rf <- randomForest(Species ~ .,
data = dt[train],
ntree = 100)
pred <- predict(rf, dt[-train])
table(pred, dt[-train, Species])
train <- sample(1:nrow(dt), 75)
# Boosting
gbm.fit <- gbm(Species ~ .,
data = dt[train],
distribution = "multinomial",
n.trees = 1000,
shrinkage = 0.002,
verbose = F)
prob <- predict(gbm.fit,
dt[-train],
n.trees = 1000,
type = "response")
results <- data.table(data.frame(prob))
names(results) <- c("setosa", "versicolor", "virginica")
results[, max := colnames(.SD)[max.col(.SD, ties.method="first")]]
results[, real := dt[-train]$Species]
table(results$max, results$real)
# bagging
require(randomForest)
bag.rf <- randomForest(Species ~ .,
data = dt[train],
ntree = 100,
mtry = 4)
pred <- predict(bag.rf, dt[-train])
table(pred, dt[-train, Species])
# randomForest
rf <- randomForest(Species ~ .,
data = dt[train],
ntree = 100)
pred <- predict(rf, dt[-train])
table(pred, dt[-train, Species])
lm.fit <- lm(Species ~ .,
data = dt[train])
?glm
lm.fit <- glm(Species ~ .,
data = dt[train], family = multinomial)
# linear regression
require(multinom)
# linear regression
install.packages("multinom")
# linear regression
lm.fit <- lm(Species ~ .,
data = dt[train])
summary(lm.fit)
# linear regression
lm.fit <- glm(Species ~ .,
data = dt[train],
family = multinomial)
# linear regression
lm.fit <- glm(Species ~ .,
data = dt[train],
family = "multinomial")
# linear regression
library(VGAM)
# linear regression
install.packages("VGAM")
library(VGAM)
lm.fit <- glm(Species ~ .,
data = dt[train],
family = multinomial)
lm.fit <- glm(Species ~ .,
family = multinomial,
data = dt[train,])
lm.fit <- glm(Species ~ .,
family = multinomial,
data = as.data.frame(dt[train,]))
lm.fit <- glm(Species ~ ,
family = multinomial,
data = as.data.frame(dt[train,]))
lm.fit <- glm(Species ~ ,
family = multinomial,
data = dt[train,])
library(VGAM)
lm.fit <- glm(Species ~ ,
family = multinomial,
data = dt[train,])
lm.fit <- glm(Species~,
family = multinomial,
data = dt[train,])
lm.fit <- glm(Species~.,
family = multinomial,
data = dt[train,])
lm.fit <- lda(Species~.,
data = dt[train,])
lda.fit <- lda(Species~.,
data = dt[train,])
pred <- predict(lda.fit, dt[-train])
pred
table(pred$class, dt[-train, Species])
# missclassification: 2/29, or 2/50
2/29
# missclassification: 2/29, or 2/50
3/30
